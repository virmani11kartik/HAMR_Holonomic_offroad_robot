#!/usr/bin/env python3
import math
import numpy as np
import os
from pathlib import Path
from functools import partial
from typing import Dict, List

import rclpy
from rclpy.node import Node
from rclpy.qos import QoSPresetProfiles
from ament_index_python.packages import get_package_share_directory
import ros2_numpy as rnp
from sensor_msgs.msg import PointCloud2, Image, CameraInfo
from sensor_msgs_py import point_cloud2
from tf_transformations import quaternion_matrix
import tf2_ros
import tf2_py as tf2
import message_filters
from cv_bridge import CvBridge
from rclpy.duration import Duration
from rclpy.serialization import serialize_message, deserialize_message
from grid_map_msgs.msg import GridMap
from grid_map_msgs.srv import SetGridMap, ProcessFile
from geometry_msgs.msg import Vector3, Quaternion
from std_msgs.msg import Float32MultiArray
from std_msgs.msg import MultiArrayLayout as MAL
from std_msgs.msg import MultiArrayDimension as MAD
import rosbag2_py
from elevation_mapping_cupy import ElevationMap, Parameter
from elevation_mapping_cupy.elevation_mapping import GridGeometry
from elevation_mapping_cupy.gridmap_utils import encode_layer_to_multiarray, decode_multiarray_to_rows_cols

PDC_DATATYPE = {
    "1": np.int8,
    "2": np.uint8,
    "3": np.int16,
    "4": np.uint16,
    "5": np.int32,
    "6": np.uint32,
    "7": np.float32,
    "8": np.float64,
}

class ElevationMappingNode(Node):
    def __init__(self):
        super().__init__(
            'elevation_mapping_node',
            automatically_declare_parameters_from_overrides=True,
            allow_undeclared_parameters=True
        )

        self.root = get_package_share_directory("elevation_mapping_cupy")
        weight_file = os.path.join(self.root, "config/core/weights.dat")
        plugin_config_file = os.path.join(self.root, "config/core/plugin_config.yaml")

        # Initialize parameters with some defaults
        self.param = Parameter(
            use_chainer=False,
            weight_file=weight_file,
            plugin_config_file=plugin_config_file
        )

        self.declare_parameter('masked_replace_service_mask_layer_name', 'mask')
        self.declare_parameter('save_map_default_topic', 'elevation_map')
        self.declare_parameter('save_map_storage_id', 'mcap')
        self.declare_parameter('service_namespace', '/elevation_mapping_cupy')

        # Read ROS parameters (including YAML)
        self.initialize_ros()
        self.set_param_values_from_ros()

        # Overwrite subscriber_cfg from loaded YAML
        self.param.subscriber_cfg = self.my_subscribers

        self.initialize_elevation_mapping()
        self.register_subscribers()
        self.register_publishers()
        self.register_timers()
        self.register_services()
        self._last_t = None

    def initialize_elevation_mapping(self) -> None:
        self.param.update()
        self._pointcloud_process_counter = 0
        self._image_process_counter = 0
        self._map = ElevationMap(self.param)
        self._map_data = np.zeros(
            (self._map.cell_n - 2, self._map.cell_n - 2), dtype=np.float32
        )
        self.get_logger().info(f"Initialized map with length: {self._map.map_length}, resolution: {self._map.resolution}, cells: {self._map.cell_n}")

        self._map_q = None
        self._map_t = None

    def initialize_ros(self) -> None:
        self._tf_buffer = tf2_ros.Buffer()
        self._listener = tf2_ros.TransformListener(self._tf_buffer, self)
        self.get_ros_params()

    def get_ros_params(self) -> None:
        self.use_chainer = self.get_parameter('use_chainer').get_parameter_value().bool_value
        self.weight_file = self.get_parameter('weight_file').get_parameter_value().string_value
        self.plugin_config_file = self.get_parameter('plugin_config_file').get_parameter_value().string_value
        self.initialize_frame_id = self.get_parameter('initialize_frame_id').get_parameter_value().string_value
        self.initialize_tf_offset = self.get_parameter('initialize_tf_offset').get_parameter_value().double_array_value
        self.map_frame = self.get_parameter('map_frame').get_parameter_value().string_value
        self.base_frame = self.get_parameter('base_frame').get_parameter_value().string_value
        self.corrected_map_frame = self.get_parameter('corrected_map_frame').get_parameter_value().string_value
        self.initialize_method = self.get_parameter('initialize_method').get_parameter_value().string_value
        self.position_lowpass_alpha = self.get_parameter('position_lowpass_alpha').get_parameter_value().double_value
        self.orientation_lowpass_alpha = self.get_parameter('orientation_lowpass_alpha').get_parameter_value().double_value
        self.recordable_fps = self.get_parameter('recordable_fps').get_parameter_value().double_value
        self.update_variance_fps = self.get_parameter('update_variance_fps').get_parameter_value().double_value
        self.time_interval = self.get_parameter('time_interval').get_parameter_value().double_value
        self.update_pose_fps = self.get_parameter('update_pose_fps').get_parameter_value().double_value
        self.initialize_tf_grid_size = self.get_parameter('initialize_tf_grid_size').get_parameter_value().double_value
        self.map_acquire_fps = self.get_parameter('map_acquire_fps').get_parameter_value().double_value
        self.publish_statistics_fps = self.get_parameter('publish_statistics_fps').get_parameter_value().double_value
        self.enable_pointcloud_publishing = self.get_parameter('enable_pointcloud_publishing').get_parameter_value().bool_value
        self.enable_normal_arrow_publishing = self.get_parameter('enable_normal_arrow_publishing').get_parameter_value().bool_value
        self.enable_drift_corrected_TF_publishing = self.get_parameter('enable_drift_corrected_TF_publishing').get_parameter_value().bool_value
        self.use_initializer_at_start = self.get_parameter('use_initializer_at_start').get_parameter_value().bool_value
        subscribers_params = self.get_parameters_by_prefix('subscribers')
        self.my_subscribers = {}
        for param_name, param_value in subscribers_params.items():
            parts = param_name.split('.')
            if len(parts) >= 2:
                sub_key, sub_param = parts[:2]
                if sub_key not in self.my_subscribers:
                    self.my_subscribers[sub_key] = {}
                self.my_subscribers[sub_key][sub_param] = param_value.value
        publishers_params = self.get_parameters_by_prefix('publishers')
        self.my_publishers = {}
        for param_name, param_value in publishers_params.items():
            parts = param_name.split('.')
            if len(parts) >= 2:
                pub_key, pub_param = parts[:2]
                if pub_key not in self.my_publishers:
                    self.my_publishers[pub_key] = {}
                self.my_publishers[pub_key][pub_param] = param_value.value


    def set_param_values_from_ros(self):
        # Assign to self.param so it won't use defaults
        # Use try/except so missing params won't cause errors
        try: self.param.resolution = self.get_parameter('resolution').get_parameter_value().double_value
        except: pass
        try: self.param.map_length = self.get_parameter('map_length').get_parameter_value().double_value
        except: pass
        try: self.param.sensor_noise_factor = self.get_parameter('sensor_noise_factor').get_parameter_value().double_value
        except: pass
        try: self.param.mahalanobis_thresh = self.get_parameter('mahalanobis_thresh').get_parameter_value().double_value
        except: pass
        try: self.param.outlier_variance = self.get_parameter('outlier_variance').get_parameter_value().double_value
        except: pass
        try: 
            # The YAML has 'drift_compensation_variance_inler', but our param is 'drift_compensation_variance_inlier'
            self.param.drift_compensation_variance_inlier = self.get_parameter('drift_compensation_variance_inler').get_parameter_value().double_value
        except: pass
        try: self.param.max_drift = self.get_parameter('max_drift').get_parameter_value().double_value
        except: pass
        try: self.param.drift_compensation_alpha = self.get_parameter('drift_compensation_alpha').get_parameter_value().double_value
        except: pass
        try: self.param.time_variance = self.get_parameter('time_variance').get_parameter_value().double_value
        except: pass
        try: self.param.max_variance = self.get_parameter('max_variance').get_parameter_value().double_value
        except: pass
        try: self.param.initial_variance = self.get_parameter('initial_variance').get_parameter_value().double_value
        except: pass
        try: self.param.traversability_inlier = self.get_parameter('traversability_inlier').get_parameter_value().double_value
        except: pass
        try: self.param.dilation_size = self.get_parameter('dilation_size').get_parameter_value().integer_value
        except: pass
        try: self.param.wall_num_thresh = self.get_parameter('wall_num_thresh').get_parameter_value().double_value
        except: pass
        try: self.param.min_height_drift_cnt = self.get_parameter('min_height_drift_cnt').get_parameter_value().double_value
        except: pass
        try: self.param.position_noise_thresh = self.get_parameter('position_noise_thresh').get_parameter_value().double_value
        except: pass
        try: self.param.orientation_noise_thresh = self.get_parameter('orientation_noise_thresh').get_parameter_value().double_value
        except: pass
        try: self.param.min_valid_distance = self.get_parameter('min_valid_distance').get_parameter_value().double_value
        except: pass
        try: self.param.max_height_range = self.get_parameter('max_height_range').get_parameter_value().double_value
        except: pass
        try: self.param.ramped_height_range_a = self.get_parameter('ramped_height_range_a').get_parameter_value().double_value
        except: pass
        try: self.param.ramped_height_range_b = self.get_parameter('ramped_height_range_b').get_parameter_value().double_value
        except: pass
        try: self.param.ramped_height_range_c = self.get_parameter('ramped_height_range_c').get_parameter_value().double_value
        except: pass
        try: self.param.max_ray_length = self.get_parameter('max_ray_length').get_parameter_value().double_value
        except: pass
        try: self.param.cleanup_step = self.get_parameter('cleanup_step').get_parameter_value().double_value
        except: pass
        try: self.param.cleanup_cos_thresh = self.get_parameter('cleanup_cos_thresh').get_parameter_value().double_value
        except: pass
        try: self.param.safe_thresh = self.get_parameter('safe_thresh').get_parameter_value().double_value
        except: pass
        try: self.param.safe_min_thresh = self.get_parameter('safe_min_thresh').get_parameter_value().double_value
        except: pass
        try: self.param.max_unsafe_n = self.get_parameter('max_unsafe_n').get_parameter_value().integer_value
        except: pass
        try: self.param.overlap_clear_range_xy = self.get_parameter('overlap_clear_range_xy').get_parameter_value().double_value
        except: pass
        try: self.param.overlap_clear_range_z = self.get_parameter('overlap_clear_range_z').get_parameter_value().double_value
        except: pass
        try: self.param.enable_edge_sharpen = self.get_parameter('enable_edge_sharpen').get_parameter_value().bool_value
        except: pass
        try: self.param.enable_visibility_cleanup = self.get_parameter('enable_visibility_cleanup').get_parameter_value().bool_value
        except: pass
        try: self.param.enable_drift_compensation = self.get_parameter('enable_drift_compensation').get_parameter_value().bool_value
        except: pass
        try: self.param.enable_overlap_clearance = self.get_parameter('enable_overlap_clearance').get_parameter_value().bool_value
        except: pass
        try: self.param.use_only_above_for_upper_bound = self.get_parameter('use_only_above_for_upper_bound').get_parameter_value().bool_value
        except: pass

        mask_param = self.get_parameter('masked_replace_service_mask_layer_name').get_parameter_value().string_value
        topic_param = self.get_parameter('save_map_default_topic').get_parameter_value().string_value
        storage_param = self.get_parameter('save_map_storage_id').get_parameter_value().string_value
        service_ns_param = self.get_parameter('service_namespace').get_parameter_value().string_value

        self.masked_replace_mask_layer_name = mask_param or 'mask'
        self.save_map_default_topic = topic_param or 'elevation_map'
        self.save_map_storage_id = storage_param or 'mcap'
        self.service_namespace = self._normalize_namespace(service_ns_param or '/elevation_mapping_cupy')

    def register_subscribers(self) -> None:
        if any(config.get("data_type") == "image" for config in self.my_subscribers.values()):
            self.cv_bridge = CvBridge()

        pointcloud_subs = {}
        image_subs = {}

        for key, config in self.my_subscribers.items():
            data_type = config.get("data_type")
            if data_type == "image":
                topic_name_camera = config.get("topic_name_camera", "/camera/image")
                topic_name_camera_info = config.get("topic_name_camera_info", "/camera/camera_info")
                camera_sub = message_filters.Subscriber(
                    self,
                    Image,
                    topic_name_camera
                )
                camera_info_sub = message_filters.Subscriber(
                    self,
                    CameraInfo,
                    topic_name_camera_info
                )
                image_sync = message_filters.ApproximateTimeSynchronizer(
                    [camera_sub, camera_info_sub], queue_size=10, slop=0.5
                )
                image_sync.registerCallback(partial(self.image_callback, sub_key=key))
                image_subs[key] = image_sync
            elif data_type == "pointcloud":
                topic_name = config.get("topic_name", "/pointcloud")
                # qos_profile = rclpy.qos.QoSProfile(
                #     depth=10,
                #     reliability=rclpy.qos.ReliabilityPolicy.BEST_EFFORT,
                #     durability=rclpy.qos.DurabilityPolicy.VOLATILE,
                #     history=rclpy.qos.HistoryPolicy.KEEP_LAST
                # )
                # qos_profile = QoSPresetProfiles.get_from_short_key("sensor_data")
                # qos_profile = rclpy.qos.QoSProfile(depth=10)
                # Use sensor data QoS (BEST_EFFORT) for point clouds
                qos_profile = QoSPresetProfiles.get_from_short_key("sensor_data")
                subscription = self.create_subscription(
                    PointCloud2,
                    topic_name,
                    partial(self.pointcloud_callback, sub_key=key),
                    qos_profile
                )
                pointcloud_subs[key] = subscription

    def register_publishers(self) -> None:
        self._publishers_dict = {}
        self._publishers_timers = []

        for pub_key, pub_config in self.my_publishers.items():
            topic_name = f"/{self.get_name()}/{pub_key}"
            publisher = self.create_publisher(GridMap, topic_name, 10)
            self._publishers_dict[pub_key] = publisher

            fps = pub_config.get("fps", 1.0)
            timer = self.create_timer(
                1.0 / fps,
                partial(self.publish_map, key=pub_key)
            )
            self._publishers_timers.append(timer)

    def register_timers(self) -> None:
        self.time_pose_update = self.create_timer(
            0.1,
            self.pose_update
        )
        self.timer_variance = self.create_timer(
            1.0 / self.update_variance_fps,
            self.update_variance
        )
        self.timer_time = self.create_timer(
            self.time_interval,
            self.update_time
        )

    def register_services(self) -> None:
        service_masked = self._resolve_service_name('masked_replace')
        service_save = self._resolve_service_name('save_map')
        service_load = self._resolve_service_name('load_map')

        self._srv_masked_replace = self.create_service(
            SetGridMap,
            service_masked,
            self.handle_masked_replace
        )
        self._srv_save_map = self.create_service(
            ProcessFile,
            service_save,
            self.handle_save_map
        )
        self._srv_load_map = self.create_service(
            ProcessFile,
            service_load,
            self.handle_load_map
        )

    def publish_map(self, key: str) -> None:
        if self._map_q is None:
            return
        center = self._get_map_center()
        gm = GridMap()
        gm.header.frame_id = self.map_frame
        gm.header.stamp = self._last_t if self._last_t is not None else self.get_clock().now().to_msg()
        gm.info.resolution = self._map.resolution
        actual_map_length = (self._map.cell_n - 2) * self._map.resolution
        gm.info.length_x = actual_map_length
        gm.info.length_y = actual_map_length
        if self._map_t is not None:
            gm.info.pose.position.x = self._map_t.x
            gm.info.pose.position.y = self._map_t.y
            gm.info.pose.position.z = self._map_t.z
        else:
            gm.info.pose.position.x = float(center[0])
            gm.info.pose.position.y = float(center[1])
            gm.info.pose.position.z = float(center[2])

        if self._map_q is not None:
            gm.info.pose.orientation.x = self._map_q.x
            gm.info.pose.orientation.y = self._map_q.y
            gm.info.pose.orientation.z = self._map_q.z
            gm.info.pose.orientation.w = self._map_q.w
        else:
            gm.info.pose.orientation.w = 1.0
            gm.info.pose.orientation.x = 0.0
            gm.info.pose.orientation.y = 0.0
            gm.info.pose.orientation.z = 0.0
        gm.layers = []
        gm.basic_layers = self.my_publishers[key]["basic_layers"]

        for layer in self.my_publishers[key].get("layers", []):
            gm.layers.append(layer)
            self._map.get_map_with_name_ref(layer, self._map_data)
            # After fixing CUDA kernels and removing flips in elevation_mapping.py, no flip needed here
            map_data_for_gridmap = self._map_data
            gm.data.append(self._numpy_to_multiarray(map_data_for_gridmap, layout="gridmap_column"))

        gm.outer_start_index = 0
        gm.inner_start_index = 0
        self._publishers_dict[key].publish(gm)

    def handle_masked_replace(self, request, response):
        try:
            layer_arrays, geometry = self._grid_map_to_numpy(request.map)
            mask = layer_arrays.pop(self.masked_replace_mask_layer_name, None)
            if not layer_arrays:
                raise ValueError("Provide at least one data layer to update.")
            self._map.apply_masked_replace(layer_arrays, mask, geometry)
            self._republish_all_once()
            self.get_logger().info(f"masked_replace updated {len(layer_arrays)} layer(s).")
        except Exception as exc:
            self.get_logger().error(f"masked_replace failed: {exc}")
        return response

    def handle_save_map(self, request, response):
        try:
            fused_path, raw_path = self._prepare_bag_paths(request.file_path)
            topic_base = request.topic_name or self.save_map_default_topic
            fused_topic = self._resolve_topic_name(topic_base)
            raw_topic = self._resolve_topic_name(f"{topic_base}_raw")

            fused_layer_names = self._collect_fused_layer_names()
            raw_layer_names = self._map.list_layers()
            self.get_logger().info(
                f"Saving map: fused layers={fused_layer_names}, raw layers={raw_layer_names}"
            )

            fused_layers = self._map.export_layers(fused_layer_names)
            raw_layers = self._map.export_layers(raw_layer_names)
            self.get_logger().info(
                f"Exported raw layer keys: {list(raw_layers.keys())}"
            )

            gm_fused = self._build_grid_map_message(
                fused_layer_names,
                fused_layers,
                self._collect_basic_layers(),
            )
            gm_raw = self._build_grid_map_message(
                raw_layer_names,
                raw_layers,
                ['elevation'],
            )
            self.get_logger().info(
                f"Built fused msg layers={gm_fused.layers}, raw msg layers={gm_raw.layers}"
            )

            self._write_grid_map_bag(fused_path, fused_topic, gm_fused)
            self._write_grid_map_bag(raw_path, raw_topic, gm_raw)

            response.success = True
        except Exception as exc:
            self.get_logger().error(f"save_map failed: {exc}")
            response.success = False
        return response

    def handle_load_map(self, request, response):
        try:
            fused_path = Path(request.file_path).expanduser().resolve()
            raw_path = Path(f"{fused_path}_raw")
            if not fused_path.exists():
                raise FileNotFoundError(f"Fused map bag '{fused_path}' does not exist.")
            if not raw_path.exists():
                raise FileNotFoundError(f"Raw map bag '{raw_path}' does not exist.")

            topic_base = request.topic_name or self.save_map_default_topic
            fused_topic = self._resolve_topic_name(topic_base)
            raw_topic = self._resolve_topic_name(f"{topic_base}_raw")

            fused_msg = self._read_latest_grid_map(fused_path, fused_topic)
            raw_msg = self._read_latest_grid_map(raw_path, raw_topic)

            fused_layers, _ = self._grid_map_to_numpy(fused_msg)
            raw_layers, geometry = self._grid_map_to_numpy(raw_msg)

            self._map.set_full_map(fused_layers, raw_layers, geometry)

            pose_position = raw_msg.info.pose.position
            pose_orientation = raw_msg.info.pose.orientation
            self._map_t = Vector3(x=pose_position.x, y=pose_position.y, z=pose_position.z)
            self._map_q = Quaternion(
                x=pose_orientation.x,
                y=pose_orientation.y,
                z=pose_orientation.z,
                w=pose_orientation.w,
            )
            self._last_t = self.get_clock().now().to_msg()
            self._republish_all_once()

            response.success = True
        except Exception as exc:
            self.get_logger().error(f"load_map failed: {exc}")
            response.success = False
        return response

    def _grid_map_to_numpy(self, grid_map_msg: GridMap):
        if len(grid_map_msg.layers) != len(grid_map_msg.data):
            raise ValueError("Mismatch between GridMap layers and data arrays.")

        arrays: Dict[str, np.ndarray] = {}
        for name, array_msg in zip(grid_map_msg.layers, grid_map_msg.data):
            arrays[name] = decode_multiarray_to_rows_cols(name, array_msg)

        center = np.array(
            [
                grid_map_msg.info.pose.position.x,
                grid_map_msg.info.pose.position.y,
                grid_map_msg.info.pose.position.z,
            ],
            dtype=np.float32,
        )
        orientation = np.array(
            [
                grid_map_msg.info.pose.orientation.x,
                grid_map_msg.info.pose.orientation.y,
                grid_map_msg.info.pose.orientation.z,
                grid_map_msg.info.pose.orientation.w,
            ],
            dtype=np.float32,
        )

        geometry = GridGeometry(
            length_x=grid_map_msg.info.length_x,
            length_y=grid_map_msg.info.length_y,
            resolution=grid_map_msg.info.resolution,
            center=center,
            orientation=orientation,
        )
        return arrays, geometry

    def _extract_layout_shape(self, array_msg: Float32MultiArray) -> tuple:
        if array_msg.layout.dim:
            cols = array_msg.layout.dim[0].size or 1
            rows = array_msg.layout.dim[1].size if len(array_msg.layout.dim) > 1 else (
                len(array_msg.data) // cols if cols else len(array_msg.data)
            )
        else:
            cols = int(math.sqrt(len(array_msg.data)))
            rows = cols
        return cols, rows

    def _collect_fused_layer_names(self) -> List[str]:
        fused: List[str] = []
        for config in self.my_publishers.values():
            fused.extend(config.get('layers', []))
        if not fused:
            fused = ['elevation']
        ordered: List[str] = []
        for name in fused:
            if name not in ordered:
                ordered.append(name)
        return ordered

    def _collect_basic_layers(self) -> List[str]:
        basics: List[str] = []
        for config in self.my_publishers.values():
            basics.extend(config.get('basic_layers', []))
        if not basics:
            basics = ['elevation']
        ordered: List[str] = []
        for name in basics:
            if name not in ordered:
                ordered.append(name)
        return ordered

    def _build_grid_map_message(
        self,
        layer_names: List[str],
        layer_data: Dict[str, np.ndarray],
        basic_layers: List[str],
    ) -> GridMap:
        gm = GridMap()
        gm.header.frame_id = self.map_frame
        gm.header.stamp = self._last_t if self._last_t is not None else self.get_clock().now().to_msg()
        gm.info.resolution = self._map.resolution
        actual_map_length = (self._map.cell_n - 2) * self._map.resolution
        gm.info.length_x = actual_map_length
        gm.info.length_y = actual_map_length

        center = self._get_map_center()
        gm.info.pose.position.x = float(center[0])
        gm.info.pose.position.y = float(center[1])
        gm.info.pose.position.z = float(center[2])
        if self._map_q is not None:
            gm.info.pose.orientation.x = self._map_q.x
            gm.info.pose.orientation.y = self._map_q.y
            gm.info.pose.orientation.z = self._map_q.z
            gm.info.pose.orientation.w = self._map_q.w
        else:
            gm.info.pose.orientation.w = 1.0

        gm.layers = []
        gm.basic_layers = basic_layers
        for name in layer_names:
            data = layer_data.get(name)
            if data is None:
                continue
            gm.layers.append(name)
            gm.data.append(self._numpy_to_multiarray(data))
        gm.outer_start_index = 0
        gm.inner_start_index = 0
        return gm

    def _numpy_to_multiarray(self, data: np.ndarray, layout: str = "gridmap_column") -> Float32MultiArray:
        return encode_layer_to_multiarray(data, layout=layout)

    def _resolve_service_name(self, suffix: str) -> str:
        base = self.service_namespace
        if not base:
            base = f"/{self.get_name()}"
        return f"{base}/{suffix}".replace('//', '/')

    def _resolve_topic_name(self, topic: str) -> str:
        topic = topic.strip('/') or self.save_map_default_topic
        base = self.service_namespace
        if not base:
            base = f"/{self.get_name()}"
        return f"{base}/{topic}".replace('//', '/')

    def _prepare_bag_paths(self, file_path: str):
        if not file_path:
            raise ValueError("file_path must be provided.")
        fused_path = Path(file_path).expanduser().resolve()
        raw_path = Path(f"{fused_path}_raw")
        if fused_path.exists():
            raise FileExistsError(f"Bag path '{fused_path}' already exists.")
        if raw_path.exists():
            raise FileExistsError(f"Bag path '{raw_path}' already exists.")
        fused_path.parent.mkdir(parents=True, exist_ok=True)
        return fused_path, raw_path

    def _make_topic_metadata(self, topic: str) -> rosbag2_py.TopicMetadata:
        """Build TopicMetadata compatible with both legacy and new rosbag2 Python signatures."""
        msg_type = 'grid_map_msgs/msg/GridMap'
        serialization_format = 'cdr'
        try:
            metadata = rosbag2_py.TopicMetadata(topic, msg_type, serialization_format, '')
            if metadata.name == topic and metadata.type == msg_type:
                return metadata
        except TypeError:
            # Older rosbag2 versions expect the reader-count placeholder as the first argument
            pass
        return rosbag2_py.TopicMetadata(0, topic, msg_type, serialization_format)

    def _write_grid_map_bag(self, path: Path, topic: str, grid_map_msg: GridMap) -> None:
        writer = rosbag2_py.SequentialWriter()
        storage_options = rosbag2_py.StorageOptions(uri=str(path), storage_id=self.save_map_storage_id)
        converter_options = rosbag2_py.ConverterOptions('', '')
        writer.open(storage_options, converter_options)
        topic_metadata = self._make_topic_metadata(topic)
        writer.create_topic(topic_metadata)
        writer.write(topic, serialize_message(grid_map_msg), self.get_clock().now().nanoseconds)

    def _read_latest_grid_map(self, path: Path, topic: str) -> GridMap:
        reader = rosbag2_py.SequentialReader()
        storage_options = rosbag2_py.StorageOptions(uri=str(path), storage_id=self.save_map_storage_id)
        converter_options = rosbag2_py.ConverterOptions('', '')
        reader.open(storage_options, converter_options)
        latest = None
        while reader.has_next():
            current_topic, data, _ = reader.read_next()
            if current_topic != topic:
                continue
            msg = deserialize_message(data, GridMap)
            latest = msg
        if latest is None:
            raise ValueError(f"No messages for topic '{topic}' in bag '{path}'.")
        return latest

    def _get_map_center(self) -> np.ndarray:
        center = np.zeros((1, 3), dtype=np.float32)
        self._map.get_center_position(center)
        return center[0]

    def _republish_all_once(self) -> None:
        if self._map_q is None:
            return
        for key in self._publishers_dict.keys():
            self.publish_map(key)

    def _normalize_namespace(self, value: str) -> str:
        value = value.strip() if value else ''
        if not value:
            return ''
        if not value.startswith('/'):
            value = f'/{value}'
        return value.rstrip('/')

    def safe_lookup_transform(self, target_frame, source_frame, time):
        try:
            return self._tf_buffer.lookup_transform(
                target_frame,
                source_frame,
                time
            )
        except tf2_ros.ExtrapolationException:
            # Time is in the future/past, try with latest available
            try:
                return self._tf_buffer.lookup_transform(
                    target_frame,
                    source_frame,
                    rclpy.time.Time()
                )
            except (tf2.LookupException, tf2.ConnectivityException) as e:
                self.get_logger().warning(
                    f"Transform from '{source_frame}' to '{target_frame}' not available: {e}",
                    throttle_duration_sec=5.0
                )
                return None
        except tf2.LookupException as e:
            # Frame doesn't exist
            self.get_logger().warning(
                f"Frame '{target_frame}' or '{source_frame}' does not exist: {e}",
                throttle_duration_sec=5.0
            )
            return None
        except tf2.ConnectivityException as e:
            # No transform path between frames
            self.get_logger().warning(
                f"No transform path from '{source_frame}' to '{target_frame}': {e}",
                throttle_duration_sec=5.0
            )
            return None
        except Exception as e:
            # Catch any other unexpected TF2 errors
            self.get_logger().warning(
                f"Unexpected TF2 error for transform from '{source_frame}' to '{target_frame}': {e}",
                throttle_duration_sec=5.0
            )
            return None

    def image_callback(self, camera_msg: Image, camera_info_msg: CameraInfo, sub_key: str) -> None:
        self._last_t = camera_msg.header.stamp
        try:
            semantic_img = self.cv_bridge.imgmsg_to_cv2(camera_msg, desired_encoding="passthrough")
        except:
            return
        if len(semantic_img.shape) != 2:
            semantic_img = [semantic_img[:, :, k] for k in range(semantic_img.shape[2])]
        else:
            semantic_img = [semantic_img]

        K = np.array(camera_info_msg.k, dtype=np.float32).reshape(3, 3)
        D = np.array(camera_info_msg.d, dtype=np.float32).reshape(-1, 1)

        transform_camera_to_map = self.safe_lookup_transform(
            self.map_frame,
            camera_msg.header.frame_id,
            camera_msg.header.stamp
        )
        if transform_camera_to_map is None:
            # Transform not available, skip this image
            return
        t = transform_camera_to_map.transform.translation
        q = transform_camera_to_map.transform.rotation
        t_np = np.array([t.x, t.y, t.z], dtype=np.float32)
        R = quaternion_matrix([q.x, q.y, q.z, q.w])[:3, :3].astype(np.float32)
        self._map.input_image(
            sub_key, semantic_img, R, t_np, K, D,
            camera_info_msg.height, camera_info_msg.width
        )
        self._image_process_counter += 1

    def pointcloud_callback(self, msg: PointCloud2, sub_key: str) -> None:
        self._last_t = msg.header.stamp
        # self.get_logger().info(f"Received pointcloud with {msg.width} points")
        additional_channels = self.param.subscriber_cfg[sub_key].get("channels", [])
        channels = ["x", "y", "z"] + additional_channels
        try:
            points = rnp.numpify(msg)
        except Exception as e:
            self.get_logger().warn(f"Failed to numpify point cloud: {e}")
            return
        
        # Check if points is empty - handle both structured array and dict cases
        if points is None:
            return
        
        # Handle different data structures from rnp.numpify
        if isinstance(points, dict):
            # If it's a dict, check if it has data
            if not points or (len(points) == 0):
                return
            # Check for x,y,z keys or xyz field in dict
            if 'xyz' in points:
                # Handle combined xyz field (common in Livox lidars)
                xyz_data = points['xyz']
                if len(xyz_data) == 0:
                    return
            elif 'x' in points:
                # Handle separate x,y,z fields
                if len(points['x']) == 0:
                    return
            else:
                self.get_logger().warn(f"Point cloud dict missing 'x' or 'xyz' field. Available fields: {list(points.keys())}")
                return
        else:
            # It's a structured numpy array
            if points.size == 0:
                return
        frame_sensor_id = msg.header.frame_id
        transform_sensor_to_map = self.safe_lookup_transform(
            self.map_frame,
            frame_sensor_id,
            msg.header.stamp
        )
        if transform_sensor_to_map is None:
            # Transform not available, skip this pointcloud
            return
        t = transform_sensor_to_map.transform.translation
        q = transform_sensor_to_map.transform.rotation
        t_np = np.array([t.x, t.y, t.z], dtype=np.float32)
        R = quaternion_matrix([q.x, q.y, q.z, q.w])[:3, :3].astype(np.float32)
        
        # Extract xyz points based on data structure
        if isinstance(points, dict):
            # If points is a dict, manually construct xyz array
            if 'xyz' in points:
                # Handle combined xyz field (common in Livox lidars)
                xyz_array = np.array(points['xyz'])
                if xyz_array.ndim == 2 and xyz_array.shape[1] == 3:
                    pts = xyz_array
                elif xyz_array.ndim == 1:
                    # Reshape if flattened
                    pts = xyz_array.reshape(-1, 3)
                else:
                    # Try to extract x, y, z from the structure
                    pts = xyz_array[:, :3] if xyz_array.shape[1] >= 3 else xyz_array
            elif 'x' in points and 'y' in points and 'z' in points:
                # Handle separate x,y,z fields
                x = np.array(points['x']).flatten()
                y = np.array(points['y']).flatten()
                z = np.array(points['z']).flatten()
                pts = np.column_stack((x, y, z))
            else:
                # Fallback: try to use any available method
                self.get_logger().warn(f"Unexpected point cloud structure, attempting fallback")
                return
            
            # Append additional channels
            for channel in additional_channels:
                if channel in points:
                    data = np.array(points[channel]).flatten()
                    if data.ndim == 1:
                        data = data[:, np.newaxis]
                    pts = np.hstack((pts, data))
        else:
            # Use standard method for structured arrays
            pts = rnp.point_cloud2.get_xyz_points(points)
            # TODO: This is probably expensive. Consider modifying rnp or input_pointcloud()
            # Append additional channels to pts
            for channel in additional_channels:
                if hasattr(points, 'dtype') and hasattr(points.dtype, 'names') and channel in points.dtype.names:
                    data = points[channel].flatten()
                    if data.ndim == 1:
                        data = data[:, np.newaxis]
                    pts = np.hstack((pts, data))
        self._map.input_pointcloud(pts, channels, R, t_np, 0, 0)
        self._pointcloud_process_counter += 1

    def pose_update(self) -> None:
        if self._last_t is None:
            return
        transform = self.safe_lookup_transform(
            self.map_frame,
            self.base_frame,
            self._last_t
        )
        if transform is None:
            # Transform not available, skip pose update
            return
        t = transform.transform.translation
        q = transform.transform.rotation
        trans = np.array([t.x, t.y, t.z], dtype=np.float32)
        rot = quaternion_matrix([q.x, q.y, q.z, q.w])[:3, :3].astype(np.float32)
        self._map.move_to(trans, rot)
        self._map_t = t
        self._map_q = q

    def update_variance(self) -> None:
        self._map.update_variance()

    def update_time(self) -> None:
        self._map.update_time()

    def destroy_node(self) -> None:
        super().destroy_node()

def main(args=None) -> None:
    rclpy.init(args=args)
    node = ElevationMappingNode()
    executor = rclpy.executors.SingleThreadedExecutor()
    executor.add_node(node)
    try:
        executor.spin()
    except KeyboardInterrupt:
        pass
    finally:
        executor.shutdown()
        node.destroy_node()
        rclpy.shutdown()

if __name__ == '__main__':
    main()
